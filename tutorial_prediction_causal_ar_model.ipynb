{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.2.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction / regression pipeline\n",
    "\n",
    "Here we try to predict y(t) based on x(s <= t). y(t) may be x(t+1)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "d_x = 1\n",
    "d_y = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Making room for the sequences\n",
    "\n",
    "Let's create placeholders for our input data x and output data y."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# We do not assume we know the sequence length yet\n",
    "\n",
    "x_seq_ph = tf.placeholder(shape=(batch_size, None, d_x), dtype=tf.float32)\n",
    "y_seq_ph = tf.placeholder(shape=(batch_size, None, d_y), dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing the network's modules\n",
    "\n",
    "Let's define a convolution layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def convolution_layer(input_seq, n_dims_in, n_dims_out, width, \n",
    "                      dilation=1, causal=True):\n",
    "    conv_kernel = tf.get_variable(\n",
    "        name=\"kernel\",\n",
    "        shape=[width, n_dims_in, n_dims_out], \n",
    "        dtype=tf.float32,\n",
    "        initializer=tf.truncated_normal_initializer())\n",
    "    \n",
    "    # Similar to approach in Francois Chollet's Keras library\n",
    "    if causal:\n",
    "        offset = dilation * (width - 1)\n",
    "        input_seq = tf.pad(input_seq, [[0, 0], [offset, 0], [0, 0]])\n",
    "    \n",
    "    conv_output = tf.nn.convolution(\n",
    "        input=input_seq,\n",
    "        filter=conv_kernel,\n",
    "        padding=\"VALID\" if causal else \"SAME\",\n",
    "        strides=None,\n",
    "        dilation_rate=[dilation]\n",
    "    )\n",
    "    \n",
    "    return conv_output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A simple auto-regressive model\n",
    "\n",
    "Let's build a AR(p) model with tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "p = 3\n",
    "\n",
    "with tf.variable_scope(\"AR_p_model\"):\n",
    "    y_predicted = convolution_layer(x_seq_ph, d_x, d_y, width=p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "loss = tf.reduce_sum(tf.nn.l2_loss(y_predicted - y_seq_ph))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "learning_rate = 1e-3\n",
    "\n",
    "optimizer = tf.train.RMSPropOptimizer(learning_rate=learning_rate).minimize(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pathological example with anti-correlated AR(1) process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generate_samples(batch_size, sequence_length, n_dims, rho=-0.2):\n",
    "    result = np.random.normal(0.0, 1.0, (batch_size, sequence_length, n_dims))\n",
    "    for t in xrange(sequence_length - 1):\n",
    "        result[:,t+1,:] += rho * result[:,t,:]\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's try to predict the next value of the process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_steps = int(1e4)\n",
    "sequence_length = 128\n",
    "\n",
    "session = tf.Session()\n",
    "\n",
    "session.run(tf.global_variables_initializer())\n",
    "\n",
    "loss_evals = []\n",
    "\n",
    "for step in xrange(n_steps):\n",
    "    x_seq = generate_samples(batch_size, sequence_length, 1)\n",
    "    \n",
    "    loss_eval, _ = session.run((loss, optimizer), \n",
    "                               feed_dict={x_seq_ph: x_seq[:,:-1],\n",
    "                                          y_seq_ph: x_seq[:,1:]})\n",
    "\n",
    "    loss_evals.append(loss_eval)\n",
    "    \n",
    "plt.plot(loss_evals)\n",
    "plt.title(\"Squared l2 loss\")\n",
    "plt.xlabel(\"SGD step\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "variables = tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES, scope=\"AR_p_model\")\n",
    "\n",
    "print([v.name for v in variables])\n",
    "kernel = [v for v in variables if \"kernel\" in v.name.split('/')[-1]][0]\n",
    "\n",
    "kernel_eval = session.run(kernel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's examine the kernel, what is going on there?\n",
    "\n",
    "Here do we get the kernel shape we expect?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(kernel_eval[:,0,0])\n",
    "plt.title(\"Trained causal kernel\")\n",
    "plt.ylabel(\"Kernel value\")\n",
    "plt.xlabel(\"Kernel component\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
